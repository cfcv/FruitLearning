{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprentissage supervis√©\n",
    "\n",
    "* 1: [Loading the database](#step1)\n",
    "* 2: [Calculation of all the image's signature](#step2)\n",
    "* 3: [Calculation of the centers of each class(boundaries)](#step3)\n",
    "* 4: [Testing the classifier](#step4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step1\"></a>\n",
    "## Loading the database "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the classifier: we will use 700 images for training and 210 for testing and cross-k validation after, saving each metric calculated\n",
    "#### For the neural network: We will use 700 images for training, 105 for validation and 105 for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read all the database files and its expected classification\n",
    "# input: path to the csv file\n",
    "# output: a list with all the images filenames\n",
    "def load_database(path):\n",
    "    file_names = []\n",
    "    targets = []\n",
    "    f = open(path, 'r')\n",
    "    \n",
    "    #split all the lines into a list\n",
    "    list_files = f.read().split('\\n')\n",
    "    \n",
    "    #scan all these lines\n",
    "    for files in list_files:\n",
    "        #split each line with a space, we get = [filename, target]\n",
    "        full_line = files.split()\n",
    "        \n",
    "        if(len(full_line) != 0):   \n",
    "            file_names.append(full_line[0])\n",
    "            targets.append(int(full_line[1]))\n",
    "            #print(full_line[0], full_line[1], i)\n",
    "    \n",
    "    f.close()\n",
    "    return file_names, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images:  910\n"
     ]
    }
   ],
   "source": [
    "filenames, targets = load_database(\"../FruitLearning/Resources/targets.csv\")\n",
    "print(\"Number of images: \", len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Calculation of all the image's signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tree_utils as tu\n",
    "from tqdm import tqdm\n",
    "\n",
    "signatures = []\n",
    "for file in filenames:#tqdm(filenames):#filenames:\n",
    "    #print(file)\n",
    "    img = cv2.imread(file)\n",
    "    if(img is None):\n",
    "        print(file)\n",
    "    else:\n",
    "        #sig_1 = tu.get_hist(tu.to_HSV(img))\n",
    "        sig_1 = tu.get_hist(img)\n",
    "        sig_2 = tu.get_LBP(tu.get_Luminance(img))\n",
    "        signatures.append([sig_1, sig_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909]\n"
     ]
    }
   ],
   "source": [
    "configuration = tu.get_nn_configuration(len(filenames))\n",
    "print(configuration[0][0][0])\n",
    "print(configuration[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "coef = [0.7, 0.3]\n",
    "confusion_matrix = np.zeros((4,4))\n",
    "right = 0\n",
    "for conf in configuration:\n",
    "    test = conf[0][0]\n",
    "    train = conf[1]\n",
    "    \n",
    "    min_dist = 1000\n",
    "    min_index = -1\n",
    "    \n",
    "    for sample in train:\n",
    "            dist = tu.distance(signatures[test], signatures[sample], coef)\n",
    "            if(dist < min_dist):\n",
    "                min_dist = dist\n",
    "                min_index = sample\n",
    "    \n",
    "    prediction = targets[min_index]\n",
    "    \n",
    "    if(prediction == targets[test]):\n",
    "        right += 1\n",
    "    confusion_matrix[targets[test]][prediction] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8362637362637363\n",
      "[[187.  25.   3.  31.]\n",
      " [ 27. 196.   5.   4.]\n",
      " [  9.   6. 188.   5.]\n",
      " [ 25.   6.   3. 190.]]\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: ', right / len(signatures))\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "coef = [0.7, 0.3]\n",
    "confusion_matrix = np.zeros((4,4))\n",
    "right = 0\n",
    "for conf in configuration:\n",
    "    test = conf[0][0]\n",
    "    train = conf[1]\n",
    "    \n",
    "    min_dist = 1000\n",
    "    min_index = -1\n",
    "    \n",
    "    for sample in train:\n",
    "            dist = tu.distance(signatures[test], signatures[sample], coef)\n",
    "            if(dist < min_dist):\n",
    "                min_dist = dist\n",
    "                min_index = sample\n",
    "    \n",
    "    prediction = targets[min_index]\n",
    "    \n",
    "    if(prediction == targets[test]):\n",
    "        right += 1\n",
    "    confusion_matrix[targets[test]][prediction] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8362637362637363\n",
      "[[187.  25.   3.  31.]\n",
      " [ 27. 196.   5.   4.]\n",
      " [  9.   6. 188.   5.]\n",
      " [ 25.   6.   3. 190.]]\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: ', right / len(signatures))\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with HSV\n",
    "import numpy as np\n",
    "coef = [0.7, 0.3]\n",
    "confusion_matrix = np.zeros((4,4))\n",
    "right = 0\n",
    "for conf in configuration:\n",
    "    test = conf[0][0]\n",
    "    train = conf[1]\n",
    "    \n",
    "    min_dist = 1000\n",
    "    min_index = -1\n",
    "    \n",
    "    for sample in train:\n",
    "            dist = tu.distance(signatures[test], signatures[sample], coef)\n",
    "            if(dist < min_dist):\n",
    "                min_dist = dist\n",
    "                min_index = sample\n",
    "    \n",
    "    prediction = targets[min_index]\n",
    "    \n",
    "    if(prediction == targets[test]):\n",
    "        right += 1\n",
    "    confusion_matrix[targets[test]][prediction] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.7758241758241758\n",
      "[[188.  24.   7.  27.]\n",
      " [ 23. 173.  28.   8.]\n",
      " [ 16.  33. 154.   5.]\n",
      " [ 21.   9.   3. 191.]]\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: ', right / len(signatures))\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids -> hsv et rgb\n",
    "1-ppv -> hsv et rgb\n",
    "5-ppv -> hsv et rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64)\n"
     ]
    }
   ],
   "source": [
    "print(signatures[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def signature_mean(list_sig):\n",
    "    sig_hist = [sig[0] for sig in list_sig]\n",
    "    sig_lbp = [sig[1] for sig in list_sig]\n",
    "    \n",
    "    return [np.mean(np.array(sig_hist), axis=0), np.mean(np.array(sig_lbp), axis=0)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910\n"
     ]
    }
   ],
   "source": [
    "print(len(signatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246\n",
      "224\n"
     ]
    }
   ],
   "source": [
    "all_index_spring_sig = [ i for i,f in enumerate(filenames) if 'spring' in f]\n",
    "all_spring_sig = [signatures[index] for index in all_index_spring_sig]\n",
    "print(len(all_spring_sig))\n",
    "\n",
    "all_index_winter_sig = [i for i,f in enumerate(filenames) if 'winter' in f]\n",
    "all_winter_sig = [signatures[index] for index in all_index_winter_sig]\n",
    "print(len(all_winter_sig))\n",
    "\n",
    "all_index_autumn_sig = [i for i,f in enumerate(filenames) if 'autumn' in f]\n",
    "all_autumn_sig = [signatures[index] for index in all_index_autumn_sig]\n",
    "\n",
    "all_index_summer_sig = [i for i,f in enumerate(filenames) if 'summer' in f]\n",
    "all_summer_sig = [signatures[index] for index in all_index_summer_sig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_spring = signature_mean(all_spring_sig)\n",
    "centroid_winter = signature_mean(all_winter_sig)\n",
    "centroid_autumn = signature_mean(all_autumn_sig)\n",
    "centroid_summer = signature_mean(all_summer_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = 0\n",
    "coef = [0.7, 0.3]\n",
    "confusion_matrix = np.zeros((4,4))\n",
    "for i,sig in enumerate(signatures):\n",
    "    dist_spring = tu.distance(centroid_spring, sig, coef)\n",
    "    dist_winter = tu.distance(centroid_winter, sig, coef)\n",
    "    dist_autumn = tu.distance(centroid_autumn, sig, coef)\n",
    "    dist_summer = tu.distance(centroid_summer, sig, coef)\n",
    "    #prediction spring = 0, summer = 1, autumn = 2, winter = 3\n",
    "    \n",
    "    if(dist_spring <= dist_winter and dist_spring <= dist_autumn and dist_spring <= dist_summer):\n",
    "        prediction = 0\n",
    "    elif(dist_summer <= dist_winter and dist_summer <= dist_spring and dist_summer <= dist_autumn):\n",
    "        prediction = 1\n",
    "    elif(dist_autumn <= dist_winter and dist_autumn <= dist_spring and dist_autumn <= dist_summer):\n",
    "        prediction = 2\n",
    "    else:\n",
    "        prediction = 3\n",
    "    \n",
    "    #check if prediction was good\n",
    "    if(prediction == targets[i]):\n",
    "        right += 1\n",
    "    confusion_matrix[targets[i]][prediction] += 1\n",
    "    #else:\n",
    "    #    print('TARGET:',targets[i])\n",
    "    #    print('distance spring:',dist_spring)\n",
    "    #    print('distance summer:',dist_summer)\n",
    "    #    print('distance autumn:', dist_autumn)\n",
    "    #    print('distance winter:',dist_winter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727\n",
      "accuracy: 0.798901098901099\n",
      "[[155.  46.   4.  41.]\n",
      " [ 10. 212.   0.  10.]\n",
      " [ 17.  17. 168.   6.]\n",
      " [ 26.   4.   2. 192.]]\n"
     ]
    }
   ],
   "source": [
    "print(right)\n",
    "print('accuracy:', right/len(targets))\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5-ppv\n",
    "import numpy as np\n",
    "coef = [0.7, 0.3]\n",
    "confusion_matrix = np.zeros((4,4))\n",
    "right = 0\n",
    "for conf in configuration:\n",
    "    test = conf[0][0]\n",
    "    train = conf[1]\n",
    "    \n",
    "    min_dist = [1000, 1000, 1000, 1000, 1000]\n",
    "    min_index = [-1, -1, -1, -1, -1]\n",
    "    \n",
    "    for sample in train:\n",
    "            dist = tu.distance(signatures[test], signatures[sample], coef)\n",
    "            index_min_element = min_dist.index(max(min_dist))\n",
    "            if(dist < min_dist[index_min_element]):\n",
    "                min_dist[index_min_element] = dist\n",
    "                min_index[index_min_element] = sample\n",
    "    \n",
    "    index_most_common = min_dist.index(most_frequent(min_dist))\n",
    "    minimun_index = min_index[index_most_common]\n",
    "    prediction = targets[minimun_index]\n",
    "    \n",
    "    if(prediction == targets[test]):\n",
    "        right += 1\n",
    "    confusion_matrix[targets[test]][prediction] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718\n",
      "accuracy: 0.789010989010989\n",
      "[[168.  37.   7.  34.]\n",
      " [ 29. 190.   6.   7.]\n",
      " [ 12.  10. 176.  10.]\n",
      " [ 31.   5.   4. 184.]]\n"
     ]
    }
   ],
   "source": [
    "print(right)\n",
    "print('accuracy:', right/len(targets))\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    " \n",
    "from collections import Counter \n",
    "  \n",
    "def most_frequent(List): \n",
    "    occurence_count = Counter(List) \n",
    "    return occurence_count.most_common(1)[0][0] \n",
    "    \n",
    "List = [2, 1, 2, 2, 1, 3] \n",
    "print(most_frequent(List)) \n",
    "print(List.index(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET: 0\n",
      "TARGET: 1\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 1\n",
      "TARGET: 1\n",
      "TARGET: 1\n",
      "TARGET: 1\n",
      "TARGET: 0\n",
      "TARGET: 2\n",
      "TARGET: 0\n",
      "TARGET: 1\n",
      "TARGET: 3\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 1\n",
      "TARGET: 1\n",
      "TARGET: 3\n",
      "TARGET: 1\n",
      "TARGET: 0\n",
      "TARGET: 1\n",
      "TARGET: 0\n",
      "TARGET: 3\n",
      "TARGET: 3\n",
      "TARGET: 3\n",
      "TARGET: 3\n",
      "TARGET: 1\n",
      "TARGET: 0\n",
      "TARGET: 3\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 2\n",
      "TARGET: 0\n",
      "TARGET: 1\n",
      "TARGET: 2\n",
      "TARGET: 0\n",
      "TARGET: 2\n",
      "TARGET: 0\n",
      "TARGET: 1\n",
      "TARGET: 2\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 2\n",
      "TARGET: 0\n",
      "TARGET: 1\n",
      "TARGET: 3\n",
      "TARGET: 0\n",
      "TARGET: 1\n",
      "TARGET: 0\n",
      "TARGET: 1\n",
      "TARGET: 2\n",
      "TARGET: 3\n",
      "TARGET: 3\n",
      "TARGET: 1\n",
      "TARGET: 0\n",
      "TARGET: 3\n",
      "TARGET: 0\n",
      "TARGET: 1\n",
      "TARGET: 3\n",
      "TARGET: 0\n",
      "TARGET: 3\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 1\n",
      "TARGET: 1\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 3\n",
      "TARGET: 1\n",
      "TARGET: 2\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 3\n",
      "TARGET: 3\n",
      "TARGET: 2\n",
      "TARGET: 1\n",
      "TARGET: 1\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 3\n",
      "TARGET: 1\n",
      "TARGET: 1\n",
      "TARGET: 3\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 3\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 3\n",
      "TARGET: 3\n",
      "TARGET: 1\n",
      "TARGET: 1\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 1\n",
      "TARGET: 0\n",
      "TARGET: 2\n",
      "TARGET: 2\n",
      "TARGET: 0\n",
      "TARGET: 2\n",
      "TARGET: 3\n",
      "TARGET: 3\n",
      "TARGET: 0\n",
      "TARGET: 3\n",
      "TARGET: 3\n",
      "TARGET: 2\n",
      "TARGET: 1\n",
      "TARGET: 1\n",
      "TARGET: 3\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 3\n",
      "TARGET: 1\n",
      "TARGET: 2\n",
      "TARGET: 2\n",
      "TARGET: 1\n",
      "TARGET: 2\n",
      "TARGET: 2\n",
      "TARGET: 1\n",
      "TARGET: 1\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 2\n",
      "TARGET: 2\n",
      "TARGET: 3\n",
      "TARGET: 2\n",
      "TARGET: 3\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 1\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 0\n",
      "TARGET: 1\n",
      "TARGET: 2\n",
      "TARGET: 0\n",
      "TARGET: 3\n",
      "TARGET: 0\n",
      "TARGET: 3\n",
      "TARGET: 3\n",
      "TARGET: 3\n",
      "756\n",
      "accuracy: 0.8307692307692308\n"
     ]
    }
   ],
   "source": [
    "right = 0\n",
    "coef = [0.8, 0.2]\n",
    "for i,sig_1 in enumerate(signatures):\n",
    "    d_min = 10000\n",
    "    index = -1\n",
    "    for j,sig in enumerate(signatures):\n",
    "        if(i == j):\n",
    "            continue\n",
    "        else:\n",
    "            dist = tu.distance(sig_1, sig, coef)\n",
    "            #prediction spring = 0, summer = 1, autumn = 2, winter = 3\n",
    "            if(dist < d_min):\n",
    "                d_min = dist\n",
    "                index = j\n",
    "\n",
    "    #check if prediction was good\n",
    "    prediction = targets[index]\n",
    "    if(prediction == targets[i]):\n",
    "        right += 1\n",
    "    else:\n",
    "        print('TARGET:',targets[i])\n",
    "        #print('distance spring:',dist_spring)\n",
    "        #print('distance summer:',dist_summer)\n",
    "        #print('distance autumn:', dist_autumn)\n",
    "        #print('distance winter:',dist_winter)\n",
    "        \n",
    "\n",
    "print(right)\n",
    "print('accuracy:', right/len(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference: ../FruitLearning/Resources/database/spring/137.png\n",
      "Winter test: ../FruitLearning/Resources/database/winter/726.png\n",
      "Spring test: ../FruitLearning/Resources/database/spring/175.png\n",
      "Summer test: ../FruitLearning/Resources/database/summer/406.png\n",
      "Autumn test: ../FruitLearning/Resources/database/autumn/622.png\n",
      "Distante to a winter: 0.5850568501035276\n",
      "Distante to a spring: 0.5850568501035276\n",
      "Distante to a summer: 0.5850568501035276\n",
      "Distante to a autumn: 0.5850568501035276\n",
      "3\n",
      "3\n",
      "663\n"
     ]
    }
   ],
   "source": [
    "print('Reference:',filenames[0])\n",
    "\n",
    "print('Winter test:',filenames[1])\n",
    "print('Spring test:',filenames[2])\n",
    "print('Summer test:',filenames[3])\n",
    "print('Autumn test:',filenames[4])\n",
    "\n",
    "#import tree_utils as tu\n",
    "dist_winter = tu.distance(centroid_winter, signatures[1], [0.8, 0.2])\n",
    "print('Distante to a winter:',dist)\n",
    "dist_spring = tu.distance(centroid_spring, signatures[1], [0.8, 0.2])\n",
    "print('Distante to a spring:',dist)\n",
    "dist_summer = tu.distance(centroid_summer, signatures[1], [0.8, 0.2])\n",
    "print('Distante to a summer:',dist)\n",
    "dist_autumn = tu.distance(centroid_autumn, signatures[1], [0.8, 0.2])\n",
    "print('Distante to a autumn:',dist)\n",
    "if(dist_spring <= dist_winter and dist_spring <= dist_autumn and dist_spring <= dist_summer):\n",
    "    prediction = 0\n",
    "elif(dist_summer <= dist_winter and dist_summer <= dist_spring and dist_summer <= dist_autumn):\n",
    "    prediction = 1\n",
    "elif(dist_autumn <= dist_winter and dist_autumn <= dist_spring and dist_autumn <= dist_summer):\n",
    "    prediction = 2\n",
    "else:\n",
    "    prediction = 3\n",
    "\n",
    "print(prediction)\n",
    "print(targets[1])\n",
    "\n",
    "if(prediction == int(targets[1])):\n",
    "    right += 1\n",
    "\n",
    "print(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distante to a winter: 0.43050714858488\n",
      "Distante to a spring: 0.3094622777727072\n",
      "Distante to a summer: 0.39922652928334057\n",
      "Distante to a autumn: 0.6052329905561256\n"
     ]
    }
   ],
   "source": [
    "dist = tu.distance(centroid_spring, signatures[1], [0.8, 0.2])\n",
    "print('Distante to a winter:',dist)\n",
    "dist = tu.distance(centroid_spring, signatures[2], [0.8, 0.2])\n",
    "print('Distante to a spring:',dist)\n",
    "dist = tu.distance(centroid_spring, signatures[3], [0.8, 0.2])\n",
    "print('Distante to a summer:',dist)\n",
    "dist = tu.distance(centroid_spring, signatures[4], [0.8, 0.2])\n",
    "print('Distante to a autumn:',dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "img = cv2.imread('../FruitLearning/Resources/database/autumn/511.jpg')\n",
    "if(img is None):\n",
    "    print(\"noen\")\n",
    "#tensor_3d = image.img_to_array(img)\n",
    "#tensor_3d.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
